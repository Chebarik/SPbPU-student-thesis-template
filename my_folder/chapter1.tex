\chapter{Обзор существующих решений и теоретических основ} \label{ch1}

В данной главе представлен обзор существующих исследований и решений в области систем управления процессами развертывания программного обеспечения. Рассматриваются теоретические основы описания процессов на базе конечных автоматов, проводится сравнительный анализ существующих платформ для управления развертыванием и оркестрации, а также исследуются подходы к управлению пакетами артефактов и потоковой передаче логов.

\section{Теоретические основы описания процессов на базе конечных автоматов} \label{ch1:sec1}

\subsection{Основные определения и формальная модель}

Конечный автомат (КА) представляет собой математическую модель вычислительной системы с конечным числом состояний, которая переходит из одного состояния в другое под воздействием входных сигналов~\cite{hopcroft-ullman, sipser-computation}. Формально детерминированный конечный автомат определяется как пятёрка $M = (Q, \Sigma, \delta, q_0, F)$, где:
\begin{itemize}
    \item $Q$ --- конечное множество состояний;
    \item $\Sigma$ --- конечный входной алфавит (множество событий);
    \item $\delta: Q \times \Sigma \rightarrow Q$ --- функция переходов;
    \item $q_0 \in Q$ --- начальное состояние;
    \item $F \subseteq Q$ --- множество финальных (допускающих) состояний.
\end{itemize}

В контексте систем управления процессами развертывания состояния автомата соответствуют этапам процесса (например, <<ожидание>>, <<выполнение>>, <<успех>>, <<ошибка>>, <<откат>>), а входной алфавит~--- множеству событий, инициирующих переходы между этапами (завершение задачи, ошибка выполнения, ручное одобрение и~т.\,д.)~\cite{fsm-habr, weyns-activforms}.

\subsection{Формальные свойства workflow и их применение к процессам развертывания}

При проектировании систем управления процессами развертывания критически важным является обеспечение ряда формальных свойств, гарантирующих корректность и надёжность работы системы~\cite{workflow-patterns, petri-nets}:

\textbf{Безопасность (Safety)} --- гарантия того, что система никогда не попадёт в недопустимое состояние. В контексте развертывания это означает невозможность перехода к следующему этапу без успешного завершения предыдущего, а также невозможность одновременного выполнения несовместимых операций.

\textbf{Живость (Liveness)} --- гарантия того, что система всегда может продолжить выполнение и не зависнет в промежуточном состоянии. Для процессов развертывания это свойство обеспечивает возможность либо успешного завершения процесса, либо его корректного прерывания с откатом изменений.

\textbf{Достижимость (Reachability)} --- свойство, определяющее возможность перехода из начального состояния в целевое состояние. Анализ достижимости позволяет верифицировать корректность определения процесса до его выполнения~\cite{aiswarya-verification, silaev-verification}.

\textbf{Отсутствие тупиков (Deadlock-freedom)} --- гарантия того, что система не может оказаться в состоянии, из которого невозможен ни один переход. Для систем развертывания это критично при организации параллельного выполнения задач и механизмов блокировок.

Исследования показывают, что применение формальных методов верификации на этапе проектирования workflow позволяет существенно снизить количество ошибок при выполнении процессов развертывания~\cite{silaev-verification, weyns-activforms}. В работе Силаева~и~др. предложен метод верификации автоматных алгоритмов по частичному описанию входных последовательностей, который может быть адаптирован для проверки корректности процессов развертывания~\cite{silaev-verification}.

\subsection{Подходы к описанию состояний и переходов}

В практике построения систем управления процессами выделяют несколько подходов к описанию состояний и переходов~\cite{fsm-yoomoney, skynet-fsm}:

\textbf{Императивный подход} предполагает явное программирование логики переходов между состояниями с использованием условных конструкций. Данный подход характеризуется высокой гибкостью, однако приводит к сложности поддержки и верификации при увеличении числа состояний.

\textbf{Декларативный подход} основан на описании допустимых переходов в виде конфигурации (таблицы переходов, графа состояний). Этот подход упрощает верификацию и визуализацию процессов, однако требует более сложной инфраструктуры для интерпретации описаний~\cite{bpmn-spec}.

\textbf{Событийно-ориентированный подход} рассматривает переходы как реакцию на события, генерируемые внешними системами или внутренними компонентами. Данный подход хорошо сочетается с микросервисной архитектурой и паттернами событийно-ориентированного программирования~\cite{taibi-devops}.

Современные библиотеки для реализации конечных автоматов, такие как Stateless для платформы~.NET, предоставляют возможность комбинирования указанных подходов: декларативное описание допустимых переходов сочетается с императивным определением действий при входе и выходе из состояний, а также условий (guard conditions) для переходов~\cite{stateless-lib}.


\section{Сравнительный анализ существующих платформ для управления развертыванием} \label{ch1:sec2}

\subsection{Классификация систем управления развертыванием}

Системы управления процессами развертывания можно классифицировать по нескольким признакам~\cite{shahin-cicd-review, rodriguez-orchestration}:

По архитектурному подходу:
\begin{itemize}
    \item централизованные системы с единым сервером управления (Jenkins, TeamCity);
    \item распределённые системы с масштабируемой архитектурой (GitLab CI/CD, GitHub Actions);
    \item cloud-native системы, ориентированные на Kubernetes (Argo CD, Tekton, Spinnaker).
\end{itemize}

По модели описания процессов:
\begin{itemize}
    \item конфигурация через пользовательский интерфейс (Octopus Deploy, Azure DevOps);
    \item конфигурация как код в формате YAML/JSON (GitHub Actions, GitLab CI/CD);
    \item программное определение через DSL или API (Jenkins Pipeline, Tekton).
\end{itemize}

По степени интеграции с инфраструктурой:
\begin{itemize}
    \item универсальные платформы (Jenkins, GitLab CI/CD);
    \item платформы, привязанные к облачному провайдеру (AWS CodePipeline, Azure DevOps);
    \item платформы для конкретной экосистемы (Argo CD для Kubernetes).
\end{itemize}

\subsection{Обзор ключевых платформ}

\textbf{Jenkins} является одной из наиболее распространённых open-source платформ для автоматизации CI/CD~\cite{jenkins-handbook}. Архитектура Jenkins основана на концепции master-agent, где центральный сервер координирует выполнение задач на распределённых агентах. Jenkins Pipeline предоставляет возможность описания процессов в виде кода на языке Groovy, поддерживая как декларативный, так и скриптовый синтаксис. К достоинствам Jenkins относятся обширная экосистема плагинов и высокая гибкость настройки. Однако система характеризуется сложностью администрирования, отсутствием встроенной модели конечных автоматов для описания workflow и ограниченными возможностями горизонтального масштабирования.

\textbf{GitLab CI/CD} представляет собой интегрированную систему непрерывной интеграции и доставки, встроенную в платформу GitLab~\cite{gitlab-cicd-docs}. Процессы описываются в файле \texttt{.gitlab-ci.yml} в декларативном формате YAML. GitLab CI/CD поддерживает концепцию stages (этапов), jobs (задач) и pipelines (конвейеров), позволяя организовать как последовательное, так и параллельное выполнение задач. Система предоставляет встроенную поддержку manual approval через механизм manual jobs, однако не имеет формальной модели конечных автоматов для описания сложных ветвлений и условных переходов.

\textbf{GitHub Actions} предлагает событийно-ориентированную модель автоматизации, где workflows запускаются в ответ на события в репозитории (push, pull request, release и др.)~\cite{github-actions-docs}. Система поддерживает декларативное описание процессов в формате YAML с возможностью определения зависимостей между jobs. К достоинствам относятся тесная интеграция с экосистемой GitHub и обширный marketplace готовых actions. Ограничениями являются привязка к платформе GitHub и отсутствие поддержки сложных workflow с множественными условными переходами.

\textbf{Octopus Deploy} представляет собой специализированную платформу для управления релизами и развертыванием~\cite{octopus-packages}. Система предоставляет развитую модель управления процессами с поддержкой environments (сред развертывания), lifecycles (жизненных циклов) и channels (каналов). Octopus Deploy реализует концепцию deployment process как последовательности шагов с поддержкой условного выполнения, manual intervention и automatic release progression. Подсистема управления пакетами поддерживает различные форматы артефактов и интеграцию с внешними репозиториями. Ограничением является проприетарная лицензия и необходимость приобретения коммерческой версии для полнофункционального использования.

\textbf{AWS CodePipeline} предоставляет сервис непрерывной доставки для AWS-инфраструктуры~\cite{aws-codepipeline-approval}. Система поддерживает модель pipeline, состоящего из stages и actions, с возможностью добавления manual approval actions для критических этапов. CodePipeline интегрируется с другими сервисами AWS (CodeBuild, CodeDeploy, S3, Lambda), обеспечивая полный цикл CI/CD в облачной среде. Ограничением является привязка к экосистеме AWS.

\textbf{Azure DevOps Pipelines} предлагает комплексное решение для CI/CD с поддержкой YAML-based pipelines и классических release pipelines~\cite{azure-devops-approvals}. Система поддерживает environments с настраиваемыми approvals и checks, deployment strategies (rolling, canary, blue-green) и интеграцию с Azure-сервисами. Azure DevOps предоставляет развитую модель approval gates с поддержкой multi-stage approvals и automated quality gates.

\textbf{Argo CD} представляет собой декларативный инструмент непрерывной доставки для Kubernetes, реализующий паттерн GitOps~\cite{argocd-docs}. Система отслеживает состояние приложений в Git-репозитории и автоматически синхронизирует его с состоянием кластера Kubernetes. Argo CD предоставляет визуализацию состояния приложений, поддержку rollback и manual sync. Ограничением является ориентация исключительно на Kubernetes-среду.

\textbf{Spinnaker} разработан компанией Netflix как платформа для multi-cloud continuous delivery~\cite{spinnaker-docs}. Система предоставляет модель pipeline с stages различных типов (deploy, manual judgment, wait, webhook и др.), поддержку deployment strategies и интеграцию с различными облачными провайдерами. Spinnaker реализует концепцию managed pipelines с expression-based условиями и pipeline templates.

\textbf{Tekton} представляет собой cloud-native framework для создания CI/CD систем на платформе Kubernetes~\cite{tekton-docs}. Система основана на концепции Tasks (задач), Pipelines (конвейеров) и PipelineRuns (запусков). Tekton использует Kubernetes CRD (Custom Resource Definitions) для декларативного описания процессов и обеспечивает нативную интеграцию с Kubernetes-инфраструктурой.

\subsection{Сравнительный анализ подходов к описанию процессов}

Систематический анализ существующих платформ позволяет выявить следующие закономерности в подходах к описанию процессов развертывания~\cite{taibi-devops, lwakatare-devops}:

Большинство современных платформ используют декларативный подход к описанию процессов в формате YAML или JSON, что обеспечивает версионирование конфигурации совместно с кодом приложения (Infrastructure as Code, Pipeline as Code). Однако декларативные форматы имеют ограничения при описании сложных условных переходов и циклов.

Механизмы ручного одобрения (manual approval) присутствуют в большинстве enterprise-платформ, однако их реализация существенно различается~--- от простых manual jobs в GitLab CI/CD до сложных approval gates с множественными условиями в Azure DevOps.

Формальная модель конечных автоматов для описания workflow в явном виде не используется ни в одной из рассмотренных платформ. Процессы представляются либо как последовательность шагов с условиями, либо как направленный ациклический граф (DAG) зависимостей между задачами. Это ограничивает возможности верификации корректности процессов и усложняет моделирование сложных сценариев с откатами и повторными попытками.

Интеграция подсистем управления процессами и управления пакетами реализована на различном уровне~--- от полной интеграции в Octopus Deploy до использования внешних репозиториев артефактов в Jenkins и GitLab CI/CD.


\section{Системы управления пакетами артефактов} \label{ch1:sec3}

\subsection{Форматы упаковки артефактов развертывания}

Артефакты развертывания могут быть представлены в различных форматах в зависимости от технологического стека и требований процесса~\cite{octopus-packages, humble-cd}:

\textbf{Архивные форматы} (ZIP, TAR, TAR.GZ) представляют собой универсальный способ упаковки файлов без специфичной для платформы метаинформации. Достоинством является простота создания и распаковки, недостатком~--- отсутствие стандартизированных механизмов версионирования и описания зависимостей.

\textbf{Platform-specific пакеты} включают форматы, специфичные для конкретных пакетных менеджеров: NuGet (.nupkg) для .NET, npm для JavaScript, PyPI для Python, Maven для Java~\cite{nuget-docs}. Данные форматы предоставляют стандартизированную структуру метаданных, механизмы версионирования и разрешения зависимостей.

\textbf{Container images} (Docker, OCI) представляют собой формат упаковки приложений вместе с их runtime-окружением~\cite{docker-registry}. Контейнерные образы обеспечивают воспроизводимость развертывания и изоляцию приложений, однако требуют инфраструктуры для хранения и запуска контейнеров.

\textbf{Helm charts} представляют собой формат упаковки приложений для Kubernetes, включающий шаблоны манифестов и конфигурацию~\cite{rodriguez-orchestration}. Helm обеспечивает параметризацию развертывания и управление релизами в Kubernetes-среде.

\subsection{Системы хранения и версионирования пакетов}

Для хранения артефактов развертывания используются специализированные репозитории пакетов~\cite{artifactory-docs, nexus-docs}:

\textbf{JFrog Artifactory} представляет собой универсальный репозиторий артефактов с поддержкой более 30 форматов пакетов~\cite{artifactory-docs}. Система предоставляет механизмы репликации, кэширования, контроля доступа и интеграции с CI/CD платформами. Artifactory поддерживает метаданные пакетов в формате JSON с возможностью кастомных полей и запросов через AQL (Artifactory Query Language).

\textbf{Sonatype Nexus Repository} предоставляет функциональность хранения и проксирования пакетов различных форматов~\cite{nexus-docs}. Система поддерживает hosted (локальные), proxy (проксирующие) и group (объединяющие) репозитории, обеспечивая гибкую организацию хранения артефактов.

\textbf{GitHub Packages} и \textbf{GitLab Container Registry} предоставляют интегрированные решения для хранения пакетов в рамках соответствующих платформ~\cite{github-packages}. Достоинством является тесная интеграция с системами контроля версий и CI/CD, недостатком~--- привязка к конкретной платформе.

\subsection{Стратегии версионирования пакетов}

Семантическое версионирование (SemVer) является де-факто стандартом версионирования программных пакетов~\cite{semver-spec, pinckney-semver}. Формат версии MAJOR.MINOR.PATCH определяет правила изменения номеров: MAJOR увеличивается при несовместимых изменениях API, MINOR~--- при добавлении обратно совместимой функциональности, PATCH~--- при исправлении ошибок.

Исследование Pinckney и др. показало, что в экосистеме npm около 40\% пакетов не соблюдают строго правила семантического версионирования, что приводит к проблемам совместимости при обновлении зависимостей~\cite{pinckney-semver}. В работе Decan и Mens исследованы особенности pre-release версий (0.y.z) и их влияние на стабильность зависимостей~\cite{decan-versioning}.

Для систем управления развертыванием важным является не только версионирование пакетов, но и версионирование процессов развертывания, что позволяет обеспечить воспроизводимость и возможность отката к предыдущим версиям процессов.


\section{Технологии распределённого кэширования и координации} \label{ch1:sec4}

\subsection{Системы распределённого кэширования}

Для обеспечения высокой производительности систем управления пакетами необходимо использование распределённого кэширования метаданных~\cite{redis-docs}:

\textbf{Redis} представляет собой in-memory хранилище данных с поддержкой различных структур (strings, hashes, lists, sets, sorted sets, streams)~\cite{redis-docs}. Redis обеспечивает высокую производительность (сотни тысяч операций в секунду), поддержку distributed locks через алгоритм Redlock, персистентность данных через RDB и AOF, кластеризацию и репликацию.

\textbf{Memcached} представляет собой высокопроизводительную систему кэширования с простым интерфейсом key-value. В отличие от Redis, Memcached не поддерживает сложные структуры данных, персистентность и distributed locks, однако обеспечивает несколько большую производительность для простых операций.

\textbf{Hazelcast} представляет собой платформу in-memory computing с поддержкой распределённых структур данных, вычислений и кэширования. Система предоставляет более широкую функциональность по сравнению с Redis, однако требует больших ресурсов и имеет более сложную конфигурацию.

\subsection{Системы распределённой координации}

Для обеспечения согласованности в распределённых системах управления процессами необходимы механизмы координации~\cite{consul-docs}:

\textbf{HashiCorp Consul} предоставляет функциональность service discovery, distributed key-value store и service mesh~\cite{consul-docs}. Consul обеспечивает консистентность данных через протокол Raft и может использоваться для хранения конфигурации, координации между узлами и реализации distributed locks.

\textbf{etcd} представляет собой распределённое key-value хранилище, используемое в Kubernetes для хранения состояния кластера. etcd обеспечивает строгую консистентность через протокол Raft и watch API для отслеживания изменений.

\textbf{Apache ZooKeeper} является системой координации для распределённых приложений, предоставляющей примитивы для синхронизации, конфигурирования и именования. ZooKeeper широко используется в экосистеме Apache (Kafka, Hadoop) и обеспечивает строгую консистентность данных.


\section{Технологии потоковой передачи логов} \label{ch1:sec5}

\subsection{Подходы к сбору и агрегации логов}

Для обеспечения наблюдаемости процессов развертывания необходимы механизмы сбора, агрегации и потоковой передачи логов выполнения~\cite{kafka-streaming}:

\textbf{WebSocket} представляет собой протокол полнодуплексной связи поверх TCP, обеспечивающий двунаправленную передачу данных в реальном времени~\cite{websocket-rfc}. WebSocket подходит для стриминга логов с низкой задержкой, однако требует поддержания постоянного соединения.

\textbf{Server-Sent Events (SSE)} представляет собой технологию однонаправленной передачи данных от сервера к клиенту через HTTP~\cite{sse-spec}. SSE проще в реализации по сравнению с WebSocket, поддерживает автоматическое переподключение, однако обеспечивает только однонаправленную связь.

\textbf{Apache Kafka} представляет собой платформу распределённого event streaming с высокой производительностью и гарантиями доставки~\cite{kafka-streaming}. Kafka обеспечивает хранение истории событий, поддержку множества потребителей и горизонтальное масштабирование. Для систем управления процессами Kafka может использоваться как для асинхронной обработки событий, так и для потоковой передачи логов.

\subsection{Архитектурные паттерны для стриминга логов}

При проектировании подсистемы стриминга логов необходимо учитывать следующие архитектурные паттерны~\cite{bass-devops, kim-devops-handbook}:

\textbf{Log aggregation} предполагает сбор логов с распределённых worker-узлов в централизованное хранилище для последующего анализа и поиска. Для реализации могут использоваться агенты (Filebeat, Fluentd) и централизованные системы (Elasticsearch, Loki).

\textbf{Real-time log streaming} обеспечивает передачу логов в реальном времени для отображения прогресса выполнения процессов. Требует организации push-модели передачи данных через WebSocket или SSE.

\textbf{Log retention и archiving} определяет политики хранения и архивирования логов для обеспечения возможности анализа исторических данных и аудита операций.


\section{Выводы} \label{ch1:conclusion}

По результатам обзора существующих решений и теоретических основ можно сделать следующие выводы:

\begin{enumerate}
    \item Теория конечных автоматов предоставляет формальный аппарат для описания процессов развертывания, обеспечивающий возможность верификации корректности, анализа достижимости состояний и гарантии формальных свойств (безопасность, живость, отсутствие тупиков).
    
    \item Существующие CI/CD платформы (Jenkins, GitLab CI/CD, GitHub Actions, Octopus Deploy) не используют формальную модель конечных автоматов в явном виде, представляя процессы как последовательность шагов или направленный ациклический граф. Это ограничивает возможности верификации и моделирования сложных сценариев.
    
    \item Механизмы ручного одобрения присутствуют в большинстве enterprise-платформ, однако их реализация существенно различается и не всегда интегрирована с моделью состояний процесса.
    
    \item Системы управления пакетами (Artifactory, Nexus, GitHub Packages) предоставляют функциональность хранения и версионирования артефактов, однако их интеграция с системами управления процессами реализована на различном уровне.
    
    \item Для обеспечения масштабируемости и производительности систем управления пакетами необходимо использование распределённого кэширования (Redis) и механизмов координации (Consul, etcd).
    
    \item Технологии потоковой передачи логов (WebSocket, SSE, Kafka) обеспечивают возможность мониторинга выполнения процессов в реальном времени и сохранения истории для аудита.
\end{enumerate}


%% Вспомогательные команды - Additional commands
%\newpage % принудительное начало с новой страницы, использовать только в конце раздела


\chapter{Критерии сравнения и подбор инструментальных средств} \label{ch2}

В данной главе представлены критерии сравнения инструментальных средств для разработки backend-системы управления процессами развертывания, а также результаты сравнительного анализа и обоснование выбора технологий.

\section{Методология выбора инструментальных средств} \label{ch2:sec1}

\subsection{Формирование критериев сравнения}

Для систематизированного сравнения инструментальных средств сформулированы следующие критерии~\cite{bass-devops, shahin-cicd-review}:

\textbf{Критерий 1: Производительность и масштабируемость.} Данный критерий оценивает способность технологии обрабатывать высокие нагрузки, возможность горизонтального масштабирования и оптимизацию для работы с большими объёмами данных. Для системы управления процессами развертывания производительность критична при обработке множества одновременных запросов от клиентов и worker-узлов.

\textbf{Критерий 2: Зрелость и стабильность.} Критерий учитывает время существования технологии на рынке, наличие стабильных релизов и долгосрочной поддержки, отсутствие критических ошибок в production-окружении и историю успешного использования в аналогичных системах.

\textbf{Критерий 3: Поддержка технологии.} Оценивается частота обновлений и патчей безопасности, качество и актуальность документации, наличие примеров использования и лучших практик.

\textbf{Критерий 4: Интеграция с экосистемой.} Критерий определяет совместимость с другими компонентами технологического стека, простоту интеграции между компонентами и наличие готовых решений для типовых задач.

\textbf{Критерий 5: Лицензирование и открытость.} В соответствии с целью создания Open Source решения оценивается наличие открытого исходного кода, отсутствие ограничений для коммерческого использования и возможность самостоятельного развертывания (self-hosted).

\textbf{Критерий 6: Сложность внедрения и обучения.} Критерий учитывает простоту настройки и конфигурации, наличие обучающих материалов и требования к инфраструктуре.

\textbf{Критерий 7: Функциональность для задач системы.} Оценивается соответствие специфическим требованиям подсистемы управления процессами и пакетами, наличие необходимых функций и возможность расширения.

\subsection{Ограничения при выборе инструментов}

На основе анализа требований к системе определены следующие ограничения:
\begin{enumerate}
    \item Должна обеспечиваться поддержка распределённой архитектуры;
    \item Выбираются только Open Source решения;
    \item Должна быть возможность self-hosted установки;
    \item Технология должна обеспечивать возможность обработки высоких нагрузок.
\end{enumerate}


\section{Сравнительный анализ и выбор языка программирования} \label{ch2:sec2}

Для разработки backend-системы рассмотрены следующие варианты языков программирования: C\# (.NET), Java (Spring Boot), Python (FastAPI), Go (Golang).

\subsection{Результаты сравнительного анализа}

\textbf{C\# (.NET)} демонстрирует положительные оценки по всем критериям. Платформа .NET обеспечивает высокую производительность, сравнимую с Java и превосходящую Python. Начиная с версии .NET 8.0, поддерживается компиляция в нативный код через AOT (Ahead-of-Time), что обеспечивает производительность, близкую к Go. C\# имеет первоклассную поддержку асинхронных паттернов (async/await), что идеально подходит для I/O-интенсивных операций~\cite{stateless-lib}.

\textbf{Java (Spring Boot)} также демонстрирует высокие показатели производительности и зрелости. Однако экосистема Spring Boot характеризуется большей сложностью настройки и традиционно ассоциируется с более высоким потреблением памяти.

\textbf{Python (FastAPI)} уступает C\# и Java в производительности вследствие интерпретируемой природы языка. Динамическая типизация увеличивает риск ошибок времени выполнения, что критично для системы управления процессами развертывания.

\textbf{Go (Golang)} обеспечивает отличную производительность и низкое потребление памяти, однако имеет более ограниченную экосистему библиотек для реализации сложной бизнес-логики.

\subsection{Обоснование выбора}

В качестве языка программирования выбран \textbf{C\# (.NET)} по следующим основаниям:
\begin{itemize}
    \item высокая производительность с поддержкой async/await для асинхронных операций;
    \item богатая экосистема библиотек (ASP.NET Core, Entity Framework Core, StackExchange.Redis);
    \item наличие библиотеки Stateless для реализации конечных автоматов с типобезопасным API~\cite{stateless-lib};
    \item открытый исходный код платформы .NET (лицензия MIT);
    \item кроссплатформенность (Windows, Linux, macOS).
\end{itemize}


\section{Сравнительный анализ и выбор СУБД} \label{ch2:sec3}

Для хранения данных о процессах, пакетах и метаданных рассмотрены следующие варианты: PostgreSQL, Microsoft SQL Server, MySQL, SQLite.

\subsection{Результаты сравнительного анализа}

\textbf{PostgreSQL} демонстрирует положительные оценки по всем критериям, кроме того, распространяется под открытой лицензией PostgreSQL License. PostgreSQL предоставляет отличную поддержку JSON и JSONB типов данных, что критично для хранения метаданных пакетов в гибком формате~\cite{pinckney-semver}.

\textbf{Microsoft SQL Server} обеспечивает высокую производительность и функциональность, однако имеет лицензионные ограничения для коммерческого использования, что противоречит требованию Open Source.

\textbf{MySQL} является открытым решением с хорошей производительностью, однако уступает PostgreSQL в поддержке сложных типов данных и возможностях расширения.

\textbf{SQLite} не подходит для многопользовательской системы из-за ограничений по масштабированию и отсутствия поддержки параллельных записей.

\subsection{Обоснование выбора}

В качестве СУБД выбран \textbf{PostgreSQL} по следующим основаниям:
\begin{itemize}
    \item открытый исходный код с лицензией, допускающей коммерческое использование;
    \item поддержка JSON/JSONB типов для гибкого хранения метаданных;
    \item высокая производительность и поддержка партиционирования;
    \item полная поддержка ACID-транзакций;
    \item отличная интеграция с Entity Framework Core через Npgsql.
\end{itemize}


\section{Сравнительный анализ и выбор ORM} \label{ch2:sec4}

Для работы с базой данных рассмотрены следующие варианты: Entity Framework Core, Dapper, NHibernate, ADO.NET.

\subsection{Обоснование выбора}

В качестве ORM выбран \textbf{Entity Framework Core} по следующим основаниям:
\begin{itemize}
    \item официальная поддержка Microsoft с регулярными обновлениями;
    \item мощная система миграций для версионирования схемы базы данных;
    \item поддержка LINQ с типобезопасными запросами;
    \item отличная поддержка JSON типов PostgreSQL;
    \item интеграция с ASP.NET Core через Dependency Injection.
\end{itemize}

Dapper обеспечивает более высокую производительность, однако не предоставляет встроенной поддержки миграций и требует написания SQL-запросов вручную, что увеличивает сложность разработки и поддержки.


\section{Сравнительный анализ и выбор библиотеки для конечных автоматов} \label{ch2:sec5}

Для реализации конечных автоматов рассмотрены следующие варианты: Stateless, Automatonymous (MassTransit), Custom Implementation, WorkflowCore.

\subsection{Обоснование выбора}

В качестве библиотеки для реализации конечных автоматов выбрана \textbf{Stateless}~\cite{stateless-lib} по следующим основаниям:
\begin{itemize}
    \item простой и интуитивный API для декларативного описания состояний и переходов;
    \item типобезопасность через generic-типы C\# для состояний и триггеров;
    \item поддержка guard-условий для реализации блокировок этапов;
    \item поддержка действий при входе и выходе из состояний;
    \item открытый исходный код (лицензия Apache 2.0);
    \item лёгкая интеграция с Entity Framework Core для персистентности состояний.
\end{itemize}

Automatonymous (MassTransit) предоставляет больше возможностей (иерархические состояния, встроенная персистентность), однако более сложна в освоении и ориентирована на интеграцию с message bus.


\section{Сравнительный анализ и выбор системы кэширования} \label{ch2:sec6}

Для распределённого кэширования метаданных пакетов и состояний процессов рассмотрены следующие варианты: Redis, Memcached, Hazelcast, In-memory кэш .NET.

\subsection{Обоснование выбора}

В качестве системы кэширования выбран \textbf{Redis}~\cite{redis-docs} по следующим основаниям:
\begin{itemize}
    \item высокая производительность (сотни тысяч операций в секунду);
    \item богатый набор структур данных (strings, hashes, lists, sets, sorted sets);
    \item поддержка distributed locks через алгоритм Redlock;
    \item поддержка персистентности данных (RDB, AOF);
    \item поддержка кластеризации и репликации;
    \item открытый исходный код (лицензия BSD);
    \item отличная интеграция с .NET через StackExchange.Redis.
\end{itemize}

Redis будет использоваться для:
\begin{enumerate}
    \item кэширования метаданных пакетов для ускорения поиска;
    \item распределённого кэширования состояний процессов;
    \item реализации distributed locks для предотвращения конфликтов при параллельных переходах FSM;
    \item хранения индексов для быстрого поиска пакетов.
\end{enumerate}


\section{Сравнительный анализ и выбор системы очередей сообщений} \label{ch2:sec7}

Для асинхронной обработки задач и координации между компонентами системы рассмотрены следующие варианты: RabbitMQ, Apache Kafka, Azure Service Bus, Redis Streams.

\subsection{Обоснование выбора}

В качестве системы очередей сообщений выбран \textbf{Apache Kafka}~\cite{kafka-streaming} по следующим основаниям:
\begin{itemize}
    \item высокая производительность (миллионы сообщений в секунду);
    \item хранение истории событий с возможностью повторной обработки;
    \item строгие гарантии доставки и упорядоченности сообщений в рамках партиции;
    \item поддержка множества независимых consumer groups;
    \item горизонтальное масштабирование через партиционирование;
    \item открытый исходный код (лицензия Apache 2.0);
    \item возможность self-hosted развертывания.
\end{itemize}

RabbitMQ проще в настройке, однако не поддерживает хранение истории событий, что критично для системы управления процессами, где важна возможность воспроизведения событий для анализа и аудита.


\section{Итоговая архитектура технологического стека} \label{ch2:sec8}

По результатам сравнительного анализа сформирован следующий технологический стек:

\begin{itemize}
    \item \textbf{Язык программирования:} C\# (.NET 8.0+)
    \item \textbf{Web-фреймворк:} ASP.NET Core
    \item \textbf{СУБД:} PostgreSQL
    \item \textbf{ORM:} Entity Framework Core
    \item \textbf{Библиотека FSM:} Stateless
    \item \textbf{Система кэширования:} Redis
    \item \textbf{Система очередей:} Apache Kafka
\end{itemize}

Данный стек соответствует всем установленным критериям и ограничениям, обеспечивая:
\begin{enumerate}
    \item высокую производительность и масштабируемость;
    \item открытость исходного кода всех компонентов;
    \item возможность self-hosted развертывания;
    \item формальное описание процессов на основе конечных автоматов;
    \item гибкое хранение метаданных пакетов;
    \item распределённое кэширование и координацию.
\end{enumerate}


\section{Выводы} \label{ch2:conclusion}

По результатам сравнительного анализа и подбора инструментальных средств можно сделать следующие выводы:

\begin{enumerate}
    \item Сформулированы семь критериев сравнения инструментальных средств, учитывающих производительность, зрелость, поддержку, интеграцию, лицензирование, сложность внедрения и функциональность.
    
    \item Определены ограничения выбора, включающие требования к распределённой архитектуре, открытости исходного кода, возможности self-hosted установки и обработки высоких нагрузок.
    
    \item Выбран технологический стек на основе платформы .NET (C\#, ASP.NET Core, Entity Framework Core), обеспечивающий высокую производительность и богатую экосистему библиотек.
    
    \item Для реализации конечных автоматов выбрана библиотека Stateless, предоставляющая типобезопасный API для декларативного описания состояний и переходов.
    
    \item Для хранения данных выбрана СУБД PostgreSQL с поддержкой JSON/JSONB типов для гибкого хранения метаданных пакетов.
    
    \item Для распределённого кэширования и координации выбран Redis, для асинхронной обработки событий~--- Apache Kafka.
\end{enumerate}


%% Вспомогательные команды - Additional commands
%\newpage % принудительное начало с новой страницы, использовать только в конце раздела


\chapter{Формулирование задачи и гипотезы решения} \label{ch3}

В данной главе формулируется постановка задачи исследования, определяются цель и задачи работы, а также формулируются гипотезы для решения поставленных задач.

\section{Постановка задачи исследования} \label{ch3:sec1}

\subsection{Определение проблемной области}

Анализ существующих решений, проведённый в главе~\ref{ch1}, показал, что современные CI/CD платформы не используют формальную модель конечных автоматов для описания процессов развертывания. Это приводит к следующим проблемам~\cite{shahin-cicd-review, taibi-devops}:

\begin{enumerate}
    \item \textbf{Сложность верификации корректности процессов.} Отсутствие формальной модели затрудняет проверку таких свойств, как отсутствие тупиковых состояний, достижимость целевых состояний и корректность переходов.
    
    \item \textbf{Ограниченные возможности моделирования сложных сценариев.} Представление процессов как последовательности шагов или DAG не позволяет адекватно моделировать сценарии с откатами, повторными попытками и условными переходами.
    
    \item \textbf{Недостаточная интеграция с подсистемами управления пакетами.} Связь между процессами развертывания и артефактами часто реализуется через внешние механизмы без формализации зависимостей.
    
    \item \textbf{Отсутствие открытых решений enterprise-уровня.} Платформы с развитой функциональностью (Octopus Deploy, Azure DevOps) являются проприетарными, что ограничивает их доступность для широкого круга организаций.
\end{enumerate}

\subsection{Цель исследования}

Целью исследования является обоснование архитектурных решений для backend-системы управления процессами развертывания приложений на основе формальной модели конечных автоматов, обеспечивающей функциональную полноту существующих решений при сохранении открытости исходного кода.

Научная новизна цели заключается в систематизации требований к подсистемам управления процессами и пакетами с точки зрения теории конечных автоматов, разработке спецификации API для взаимодействия компонентов и формулировании рекомендаций по выбору технологий для распределённого кэширования, индексации метаданных и потоковой передачи логов выполнения.

Практическая значимость цели определяется возможностью использования полученных результатов для создания конкурентоспособной Open Source платформы управления развертыванием, доступной широкому кругу организаций и индивидуальных разработчиков.


\section{Задачи исследования} \label{ch3:sec2}

Для достижения поставленной цели необходимо решить следующие задачи, сформулированные по принципу от наименее сложных к наиболее сложным:

\textbf{Задача 1.} Провести анализ существующих инструментов и платформ для управления процессами развертывания и оркестрации.

\textit{Обоснование:} Данная задача направлена на изучение предметной области и выявление требований к системе на основе анализа существующих решений. Это базовая задача, необходимая для понимания функциональных возможностей, архитектурных паттернов и ограничений существующих систем~\cite{shahin-cicd-review, rodriguez-orchestration}.

\textbf{Задача 2.} Исследовать и систематизировать теоретические основы описания процессов, включая теорию конечных автоматов, формальные свойства workflow и подходы к описанию состояний и переходов.

\textit{Обоснование:} Понимание формальных моделей описания процессов необходимо для обоснованного применения теории конечных автоматов к задаче управления процессами развертывания~\cite{hopcroft-ullman, workflow-patterns}.

\textbf{Задача 3.} Исследовать практические модели описания шагов процессов развертывания и форматы представления процессов, провести их сопоставление с теорией конечных автоматов.

\textit{Обоснование:} Необходимо установить связь между теоретическими основами и практическими реализациями, исследовать форматы описания workflow (YAML, JSON, DSL) и их соответствие формальной модели~\cite{bpmn-spec, sadik-bpmn-fsm}.

\textbf{Задача 4.} Проанализировать форматы упаковки и распространения артефактов развертывания, а также провести сравнительный обзор систем хранения и версионирования пакетов.

\textit{Обоснование:} Эффективное управление артефактами критично для обеспечения целостности и воспроизводимости процессов развертывания~\cite{pinckney-semver, decan-versioning}.

\textbf{Задача 5.} Исследовать методы выполнения bash-скриптов на исполняющих машинах (worker-узлах) с обеспечением изоляции и безопасности.

\textit{Обоснование:} Большинство процессов развертывания включают выполнение скриптов на удалённых машинах, что требует обеспечения изоляции, безопасности и контроля выполнения~\cite{humble-cd, bass-devops}.

\textbf{Задача 6.} Провести обзор технологий для распределённого согласования и кэширования, проанализировать стратегии индексации, кэширования и распределения метаданных пакетов.

\textit{Обоснование:} Для обеспечения масштабируемости и производительности необходимо использовать распределённое кэширование метаданных и механизмы координации~\cite{redis-docs, consul-docs}.

\textbf{Задача 7.} Исследовать подходы к сбору, агрегации и стримингу логов выполнения процессов в реальном времени.

\textit{Обоснование:} Для эффективного управления процессами развертывания необходимо обеспечить возможность мониторинга выполнения в реальном времени~\cite{kafka-streaming, websocket-rfc}.

\textbf{Задача 8.} Сформировать требования к API взаимодействия подсистем управления процессами и управления пакетами.

\textit{Обоснование:} Интеграция подсистем является критичной для обеспечения целостности deployment pipeline~\cite{lwakatare-devops}.

\textbf{Задача 9.} Систематизировать результаты анализа и сформировать требования к архитектуре компонентов управления процессами и управления пакетами.

\textit{Обоснование:} Интеграционная задача, направленная на обобщение результатов всех предыдущих исследований~\cite{kim-devops-handbook}.


\section{Гипотезы исследования} \label{ch3:sec3}

Для решения поставленных задач сформулированы следующие гипотезы:

\subsection{Гипотеза 1: Формализация процессов на основе конечных автоматов}

\textit{Формулировка:} Использование конечных автоматов для описания процессов развертывания позволит строго проверить корректность процессов, предсказать поведение системы и проанализировать её безопасность и работоспособность.

\textit{Обоснование:} Конечные автоматы представляют собой математический аппарат описания систем с конечным числом состояний и детерминированными переходами между ними~\cite{hopcroft-ullman}. При описании процессов развертывания это означает явное определение всех возможных состояний процесса и правил переходов между ними. Формальное описание позволяет заранее проверить, что процесс не может попасть в недопустимое состояние, и гарантирует предсказуемое поведение системы~\cite{silaev-verification, weyns-activforms}.

\textit{Критерий проверки:} Возможность автоматической верификации свойств процесса (отсутствие тупиков, достижимость финальных состояний) до его выполнения.

\subsection{Гипотеза 2: Персистентность состояний и распределённая координация}

\textit{Формулировка:} Сохранение состояний процессов в долговременном хранилище вместе с механизмами координации между узлами системы обеспечит надёжность и устойчивость к сбоям системы управления процессами.

\textit{Обоснование:} В распределённой системе критично сохранение состояний процессов между перезапусками и предотвращение конфликтов при параллельных операциях. Сохранение состояний в базе данных позволяет восстановить работу после сбоя и продолжить выполнение процессов. Механизмы координации (distributed locks) предотвращают ситуации, когда несколько узлов одновременно пытаются изменить состояние одного процесса~\cite{redis-docs, consul-docs}.

\textit{Критерий проверки:} Корректное восстановление состояния процессов после сбоя узла системы без потери данных и дублирования операций.

\subsection{Гипотеза 3: Гибкое хранение метаданных с многоуровневым кэшированием}

\textit{Формулировка:} Использование гибкого формата хранения метаданных пакетов вместе с кэшированием на нескольких уровнях позволит быстро находить пакеты и масштабировать систему при росте их количества.

\textit{Обоснование:} Метаданные различных пакетов могут иметь различную структуру в зависимости от типа пакета. Гибкий формат хранения (JSON/JSONB в PostgreSQL) позволяет хранить метаданные различной структуры с возможностью эффективного поиска. Многоуровневое кэширование (in-memory, Redis, база данных) обеспечивает быстрый доступ к часто запрашиваемым данным~\cite{pinckney-semver, artifactory-docs}.

\textit{Критерий проверки:} Линейное масштабирование времени поиска пакетов при росте объёма данных за счёт кэширования.

\subsection{Гипотеза 4: Потоковая передача логов с сохранением истории}

\textit{Формулировка:} Сбор, агрегация и потоковая передача логов выполнения процессов в реальном времени с сохранением истории позволит эффективно мониторить выполнение процессов развертывания, анализировать проблемы и проводить аудит операций.

\textit{Обоснование:} Для эффективного управления процессами необходима возможность наблюдения за выполнением в реальном времени. Агрегация логов с различных worker-узлов в централизованное хранилище позволяет получить полную картину выполнения. Потоковая передача логов через WebSocket или SSE обеспечивает отображение прогресса. Сохранение истории логов важно для анализа проблем и аудита~\cite{kafka-streaming, websocket-rfc}.

\textit{Критерий проверки:} Задержка передачи логов от worker-узла до клиента не более 1 секунды, полнота сохранения истории логов.

\subsection{Гипотеза 5: Версионируемый API взаимодействия подсистем}

\textit{Формулировка:} Чётко определённый интерфейс взаимодействия между подсистемами управления процессами и управления пакетами с поддержкой версий и зависимостей обеспечит правильную работу процессов развертывания и возможность независимого развития компонентов.

\textit{Обоснование:} Каждый шаг процесса развертывания должен получить правильную версию пакета, поэтому подсистемы управления процессами и пакетами должны тесно взаимодействовать. Чётко определённый API с поддержкой версий позволяет компонентам развиваться независимо. Поддержка зависимостей между пакетами критична для обеспечения совместимости версий~\cite{semver-spec, decan-versioning}.

\textit{Критерий проверки:} Возможность обновления одной подсистемы без нарушения работы другой при сохранении совместимости API.


\section{Планируемые результаты исследования} \label{ch3:sec4}

На основе поставленных задач и сформулированных гипотез определены следующие планируемые результаты исследования:

\begin{enumerate}
    \item Систематизированный обзор источников и литературы по моделям workflow, теории конечных автоматов и подходам к построению систем управления процессами развертывания.
    
    \item Сравнительный анализ существующих решений для управления процессами и пакетами с выделением архитектурных паттернов и ограничений.
    
    \item Рекомендации по практическим моделям описания шагов процессов и их соответствию формальной модели конечных автоматов.
    
    \item Спецификация требований к API взаимодействия подсистем управления процессами и управления пакетами.
    
    \item Рекомендации по выбору форматов пакетов, стратегий версионирования и подходов к кэшированию метаданных.
    
    \item Анализ подходов к сбору, агрегации и потоковой передаче логов в реальном времени.
    
    \item Итоговые требования к архитектуре, технологиям и подходам для реализации системы управления процессами развертывания.
\end{enumerate}


\section{Выводы} \label{ch3:conclusion}

По результатам формулирования задачи и гипотез исследования можно сделать следующие выводы:

\begin{enumerate}
    \item Определена цель исследования~--- обоснование архитектурных решений для backend-системы управления процессами развертывания на основе формальной модели конечных автоматов.
    
    \item Сформулированы девять задач исследования, охватывающих теоретические основы, анализ существующих решений, подбор технологий и формирование требований к архитектуре.
    
    \item Сформулированы пять гипотез, определяющих ключевые архитектурные решения: формализация процессов на основе FSM, персистентность состояний, гибкое хранение метаданных, потоковая передача логов и версионируемый API.
    
    \item Для каждой гипотезы определены критерии проверки, позволяющие оценить её справедливость по результатам экспериментальной реализации.
    
    \item Определены планируемые результаты исследования, включающие обзор литературы, сравнительный анализ, спецификацию API и итоговые требования к архитектуре.
\end{enumerate}

Сформулированные задачи и гипотезы определяют направление дальнейшей работы по проектированию и экспериментальной реализации прототипа системы управления процессами развертывания.


%% Вспомогательные команды - Additional commands
%\newpage % принудительное начало с новой страницы, использовать только в конце раздела
